{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "minus-synthesis",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import mediapipe as mp\n",
    "from IPython.display import clear_output\n",
    "import IPython.display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "comfortable-america",
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_hands = mp.solutions.hands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "handed-arthur",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_landmark(landmark):\n",
    "    wrist = landmark[0]\n",
    "    thump = landmark[1:5]\n",
    "    index_finger = landmark[5:9]\n",
    "    middle_finger = landmark[9:13]\n",
    "    ring_finger = landmark[13:17]\n",
    "    pinky = landmark[17:21]\n",
    "    return [wrist, thump, index_finger, middle_finger, ring_finger, pinky]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "proof-murray",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_on(idx, finger, landmark_label):\n",
    "    if idx == 0:\n",
    "        if landmark_label == \"Right\":\n",
    "            if finger[-1].x < finger[-2].x:\n",
    "                return True\n",
    "            else:\n",
    "                return False\n",
    "        else:\n",
    "            if finger[-1].x < finger[-2].x:\n",
    "                return False\n",
    "            else:\n",
    "                return True\n",
    "    else:\n",
    "        if -finger[-1].y > -finger[0].y:\n",
    "            return True\n",
    "        else:\n",
    "            return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "funded-while",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gesture_recognition(finger_is_on):\n",
    "    thump_is_on = finger_is_on[0]\n",
    "    index_finger_is_on = finger_is_on[1]\n",
    "    middle_finger_is_on = finger_is_on[2]\n",
    "    ring_finger_is_on = finger_is_on[3]\n",
    "    pinky_is_on = finger_is_on[4]\n",
    "    \n",
    "    if thump_is_on:\n",
    "        if index_finger_is_on and middle_finger_is_on and ring_finger_is_on and pinky_is_on:\n",
    "            return 5\n",
    "        elif index_finger_is_on and middle_finger_is_on and ring_finger_is_on and not pinky_is_on:\n",
    "            return 9\n",
    "        elif index_finger_is_on and middle_finger_is_on and not ring_finger_is_on and not pinky_is_on:\n",
    "            return 8\n",
    "        elif index_finger_is_on and not middle_finger_is_on and not ring_finger_is_on and not pinky_is_on:\n",
    "            return 7\n",
    "        elif not index_finger_is_on and not middle_finger_is_on and not ring_finger_is_on and not pinky_is_on:\n",
    "            return 6\n",
    "        else:\n",
    "            return \"Wrong Gesture\"\n",
    "        \n",
    "    else:\n",
    "        if index_finger_is_on and middle_finger_is_on and ring_finger_is_on and pinky_is_on:\n",
    "            return 4\n",
    "        elif index_finger_is_on and middle_finger_is_on and ring_finger_is_on and not pinky_is_on:\n",
    "            return 3\n",
    "        elif index_finger_is_on and middle_finger_is_on and not ring_finger_is_on and not pinky_is_on:\n",
    "            return 2\n",
    "        elif index_finger_is_on and not middle_finger_is_on and not ring_finger_is_on and not pinky_is_on:\n",
    "            return 1\n",
    "        elif not index_finger_is_on and not middle_finger_is_on and not ring_finger_is_on and not pinky_is_on:\n",
    "            return 0\n",
    "        else:\n",
    "            return \"Wrong Gesture\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "known-safety",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recognition(landmark, handness):\n",
    "    landmark = landmark.landmark\n",
    "    handness = handness.classification[0].label\n",
    "    \n",
    "    hand_landmark = classify_landmark(landmark)\n",
    "    finger_landmark = hand_landmark[1:]\n",
    "    \n",
    "    finger_is_on = []\n",
    "    for idx, finger in enumerate(finger_landmark):\n",
    "        finger_is_on.append(is_on(idx, finger, handness))\n",
    "     \n",
    "    return gesture_recognition(finger_is_on)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "posted-istanbul",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_output(idx):\n",
    "    global _output, output\n",
    "    key = []\n",
    "    for i in range(len(_output[idx])):\n",
    "        if _output[idx][i] not in key:\n",
    "            c = _output[idx].count(_output[idx][i])\n",
    "            if c > 10:\n",
    "                key.append(_output[idx][i])           \n",
    "    floor = \"\"\n",
    "    for i in key:\n",
    "        if i == \"Wrong Gesture\":\n",
    "            continue\n",
    "        floor += str(i)\n",
    "    if floor == \"\":\n",
    "        return None\n",
    "    output.append(floor)\n",
    "    _output[idx] = []\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "grand-capability",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_euclidean_distance(a, b):\n",
    "    return np.linalg.norm(a - b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "smaller-sampling",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(image, results):\n",
    "    global mp_drawing, current_hand \n",
    "    global output, _output\n",
    "    global mean_xy\n",
    "    \n",
    "    multi_hand_landmarks = results.multi_hand_landmarks\n",
    "    multi_handedness = results.multi_handedness\n",
    "    \n",
    "    _mean_xy = []\n",
    "    _gesture = []\n",
    "    \n",
    "    isIncreased = False\n",
    "    isDecreased = False\n",
    "            \n",
    "    if current_hand != 0:\n",
    "        if results.multi_hand_landmarks is None:\n",
    "            isDecreased = True\n",
    "        else:\n",
    "            if len(multi_hand_landmarks) > current_hand:\n",
    "                isIncreased = True\n",
    "            elif len(multi_hand_landmarks) < current_hand:\n",
    "                isDecreased = True\n",
    "           \n",
    "    if results.multi_hand_landmarks:\n",
    "    \n",
    "        h, w, _ = image.shape\n",
    "        for idx in reversed(range(len(multi_hand_landmarks))):\n",
    "            mp_drawing.draw_landmarks(image, multi_hand_landmarks[idx], mp_hands.HAND_CONNECTIONS)\n",
    "\n",
    "            min_x = int(min([multi_hand_landmarks[idx].landmark[i].x for i in range(len(multi_hand_landmarks[idx].landmark))])*w)\n",
    "            max_x = int(max([multi_hand_landmarks[idx].landmark[i].x for i in range(len(multi_hand_landmarks[idx].landmark))])*w)\n",
    "            min_y = int(min([multi_hand_landmarks[idx].landmark[i].y for i in range(len(multi_hand_landmarks[idx].landmark))])*h)\n",
    "            max_y = int(max([multi_hand_landmarks[idx].landmark[i].y for i in range(len(multi_hand_landmarks[idx].landmark))])*h)\n",
    "\n",
    "            cv2.rectangle(image, (min_x-10, min_y-10), (max_x+10, max_y+10), (0, 255, 255), 2)\n",
    "\n",
    "            gesture = recognition(multi_hand_landmarks[idx], multi_handedness[idx])\n",
    "\n",
    "            order_text = \"No.{} hand\".format(idx)\n",
    "            cv2.putText(image, order_text, (min_x-10, max_y+30), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 255), 2)\n",
    "\n",
    "            gesture_text = \"Gesture: {}\".format(gesture)\n",
    "            cv2.putText(image, gesture_text, (min_x-10, max_y+60), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 255), 2)\n",
    "\n",
    "            handness_text = \"This is {} hand\".format(multi_handedness[idx].classification[0].label)\n",
    "            cv2.putText(image, handness_text, (min_x-10, max_y+90), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 255), 2)\n",
    "\n",
    "            _mean_xy.append(np.array([(min_x+max_x)/2, (min_y+max_y)/2]))\n",
    "            _gesture.append(gesture)                        \n",
    "        \n",
    "    if isIncreased == True:\n",
    "        mean_xy[0] = _mean_xy[0]\n",
    "        if current_hand == 1:  \n",
    "            mean_xy[1] = _mean_xy[1]\n",
    "\n",
    "    elif isDecreased == True:\n",
    "        if current_hand == 1:\n",
    "            get_output(0)\n",
    "        elif current_hand == 2:\n",
    "            vanishing_index = find_vanishing(_mean_xy)\n",
    "            get_output(vanishing_index)\n",
    "    else:\n",
    "        if results.multi_hand_landmarks is not None:\n",
    "            mean_xy[0] = _mean_xy[0]\n",
    "            _output[0].append(_gesture[0])\n",
    "            \n",
    "            if current_hand == 2:\n",
    "                mean_xy[1] = _mean_xy[1]\n",
    "                _output[1].append(_gesture[1])\n",
    "    \n",
    "    if results.multi_hand_landmarks:\n",
    "        current_hand = len(multi_hand_landmarks)\n",
    "    else:\n",
    "        current_hand = 0\n",
    "\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "talented-despite",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_appearing(_mean_xy):\n",
    "    global mean_xy\n",
    "    \n",
    "    _a = get_euclidean_distance(mean_xy[0], _mean_xy[0])\n",
    "    _b = get_euclidean_distance(mean_xy[1], _mean_xy[0])\n",
    "    \n",
    "    if _a > _b:\n",
    "        mean_xy[0] = mean_xy[1]\n",
    "        mean_xy[1] = []\n",
    "        return 0\n",
    "    else:\n",
    "        mean_xy[1] = []\n",
    "        return 1  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "loving-leather",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_vanishing(_mean_xy):\n",
    "    global mean_xy\n",
    "    \n",
    "    _a = get_euclidean_distance(mean_xy[0], _mean_xy[0])\n",
    "    _b = get_euclidean_distance(mean_xy[1], _mean_xy[0])\n",
    "    \n",
    "    if _a > _b:\n",
    "        mean_xy[0] = mean_xy[1]\n",
    "        mean_xy[1] = []\n",
    "        return 0\n",
    "    else:\n",
    "        mean_xy[1] = []\n",
    "        return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "driving-expansion",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(1)\n",
    "output = []\n",
    "_output = [[], []]\n",
    "mean_xy = [[], []]\n",
    "current_hand = 0\n",
    "\n",
    "with mp_hands.Hands(\n",
    "    min_detection_confidence=0.5,\n",
    "    min_tracking_confidence=0.5, \n",
    "    max_num_hands = 2) as hands:\n",
    "    while cap.isOpened():\n",
    "        success, image = cap.read()\n",
    "        if not success:\n",
    "            print(\"Ignoring empty camera frame.\")\n",
    "            continue\n",
    "\n",
    "        # Flip the image horizontally for a later selfie-view display, and convert the BGR image to RGB.\n",
    "        image = cv2.cvtColor(cv2.flip(image, 1), cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        # To improve performance, optionally mark the image as not writeable to pass by reference.\n",
    "        image.flags.writeable = False\n",
    "        results = hands.process(image)\n",
    "\n",
    "        # Draw the hand annotations on the image.\n",
    "        image.flags.writeable = True\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "        \n",
    "        try:\n",
    "            image = main(image, results)\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            \n",
    "        number_text = str(output)\n",
    "        cv2.putText(image, number_text, (10, 15), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 255), 2)\n",
    "        cv2.imshow('MediaPipe Hands', image)\n",
    "        \n",
    "        if cv2.waitKey(5) & 0xFF == 27:\n",
    "            break\n",
    "            \n",
    "cv2.destroyAllWindows()\n",
    "cap.release()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
